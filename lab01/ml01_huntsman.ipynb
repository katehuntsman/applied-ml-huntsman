{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huntsman California Housing Price Prediction\n",
    "**Author:** Kate Huntsman\n",
    "**Date:** March 10th, 2025  \n",
    "**Objective:** Predict the median house price in California using available housing features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project leverages the California housing dataset to forecast property prices, utilizing factors like median income, average room count, and the age of the houses. My approach includes data preprocessing, training a linear regression model, and experimenting with techniques to enhance its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "In the code cell below, import the necessary Python libraries for this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c36c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Python cell\n",
    "# All imports should be at the top of the notebook\n",
    "# This cell will be executed when the notebook is loaded\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib for creating static visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import seaborn for statistical data visualization (built on matplotlib)\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the California housing dataset from sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Import train_test_split for splitting data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LinearRegression for building a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import performance metrics for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32bf5e",
   "metadata": {},
   "source": [
    "## Section 1. Load and Explore the Data\n",
    "\n",
    "### 1.1 Load the dataset and display the first 10 rows\n",
    "Load the California housing dataset directly from `scikit-learn`.\n",
    "- The `fetch_california_housing` function returns a dictionary-like object with the data.\n",
    "- Convert it into a pandas DataFrame.\n",
    "- Display just the first 10 rows using `head()`.\n",
    "\n",
    "Example code:\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "data_frame = data.frame\n",
    "\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847cd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "data_frame = data.frame\n",
    "\n",
    "# Might be large. Display just the first 10 rows (you can change this number)\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b9568",
   "metadata": {},
   "source": [
    "### 1.2 Check for missing values and display summary statistics\n",
    "\n",
    "In the cell below:\n",
    "1. Use `info()` to check data types and missing values.\n",
    "2. Use `describe()` to see summary statistics.\n",
    "3. Use `isnull().sum()` to identify missing values in each column.\n",
    "\n",
    "Example code:\n",
    "\n",
    "data_frame.info()\n",
    "\n",
    "data_frame.describe()\n",
    "\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the California housing dataset\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "data_frame = california_housing.frame\n",
    "\n",
    "# 1. Use info() to check data types and missing values\n",
    "print(\"Data Types and Missing Values:\")\n",
    "data_frame.info()\n",
    "\n",
    "# 2. Use describe() to see summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data_frame.describe())\n",
    "\n",
    "# 3. Use isnull().sum() to identify missing values in each column\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(data_frame.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c001a63",
   "metadata": {},
   "source": [
    "Analysis: \n",
    "\n",
    "1) How many data instances (also called data records or data rows) are there? 20,640\n",
    "\n",
    "2) How many features (also columns or attributes) are there? 9\n",
    "\n",
    "3) What are the names of the features? (\"Feature\" is used most often in ML projects.) \n",
    "MedInc\n",
    "HouseAge\n",
    "AveRooms\n",
    "AveBedrms\n",
    "Population\n",
    "AveOccup\n",
    "Latitude\n",
    "Longitude\n",
    "MedHouseVal\n",
    "\n",
    "4) Which features are numeric? all 9 are numeric (float64 data type)\n",
    "\n",
    "5) Which features are categorical (non-numeric)? none\n",
    "\n",
    "6) Are there any missing values? How should they be handled? Should we delete a sparsely populated column? Delete an incomplete data row? Substitute with a different value? \n",
    "All columns have 20640 non-null entries, meaning there are no missing values in the dataset.\n",
    "Thus, no handling of missing values is needed (no need to delete rows or columns, or substitute values).\n",
    "\n",
    "7) What else do you notice about the dataset? Are there any data issues? \n",
    "The dataset is clean with no missing values, making it straightforward to work with. All features are numeric, and there are no categorical attributes. Some features, like `Population`, have a wide range of values, which might indicate potential outliers or skewness. It’s worth investigating possible correlations between features to avoid multicollinearity in future analysis. Overall, the dataset appears ready for analysis, though further exploration for outliers or data transformations may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a04934",
   "metadata": {},
   "source": [
    "## Section 2. Visualize Feature Distributions\n",
    "### 2.1 Create histograms, boxplots, and scatterplots\n",
    "\n",
    "- Create histograms for all numeric features using `data_frame.hist()` with 30 bins.\n",
    "- Create a boxenplots using `sns.boxenplot()`.\n",
    "- Create scatter plots using `sns.pairplot()`.\n",
    "\n",
    "First, histograms\n",
    "\n",
    "Generate histograms for all numerical columns\n",
    "\n",
    "Example code:\n",
    "\n",
    "data_frame.hist(bins=30, figsize=(12, 8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for all numeric features\n",
    "data_frame.hist(bins=30, figsize=(12, 8))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4a38b",
   "metadata": {},
   "source": [
    "Generate one Boxenplot for each column (good for large datasets)\n",
    "\n",
    "Example code:\n",
    "\n",
    "for column in data_frame.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxenplot(data=data_frame[column])\n",
    "    plt.title(f'Boxenplot for {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxenplots for each numeric feature\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(data_frame.select_dtypes(include=[np.number]).columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxenplot(data=data_frame, x=column)\n",
    "    plt.title(f\"Boxenplot for {column}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad19958",
   "metadata": {},
   "source": [
    "Third - Scatter Plots\n",
    "\n",
    "Generate all Scatter plots (there is a LOT of data, so this will take a while)\n",
    "\n",
    "Comment out after analysis to speed up the notebook.\n",
    "\n",
    "Example code:\n",
    "\n",
    "sns.pairplot(data_frame)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot for scatter plots between numeric features\n",
    "sns.pairplot(data_frame)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661b3e6",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "### 3.1 Choose two input features for predicting the target\n",
    "\n",
    "- Select `MedInc` and `AveRooms` as predictors.\n",
    "- Select `MedHouseVal` as the target variable.\n",
    "\n",
    "In the following, \n",
    "X is capitalized because it represents a matrix (consistent with mathematical notation).\n",
    "y is lowercase because it represents a vector (consistent with mathematical notation).\n",
    "\n",
    "\n",
    "First:\n",
    "- Create a list of contributing features and the target variable\n",
    "- Define the target feature string (the variable we want to predict)\n",
    "- Define the input DataFrame\n",
    "- Define the output DataFrame\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "features: list = ['MedInc', 'AveRooms']\n",
    "\n",
    "target: str = 'MedHouseVal'\n",
    "\n",
    "df_X = data_frame[features]\n",
    "\n",
    "df_y = data_frame[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of contributing features (input variables)\n",
    "features = ['MedInc', 'AveRooms']\n",
    "\n",
    "# Define the target variable (the variable we want to predict)\n",
    "target = 'MedHouseVal'\n",
    "\n",
    "# Define the input DataFrame (X) using the selected features\n",
    "df_X = data_frame[features]\n",
    "\n",
    "# Define the output DataFrame (y) using the target variable\n",
    "df_y = data_frame[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866eec6",
   "metadata": {},
   "source": [
    "## Section 4. Train a Linear Regression Model\n",
    "### 4.1 Split the data\n",
    "Split the dataset into training and test sets (80% train / 20% test).\n",
    "\n",
    "Call train_test_split() by passing in: \n",
    "\n",
    "- df_X – Feature matrix (input data) as a pandas DataFrame\n",
    "- y – Target values as a pandas Series\n",
    "- test_size – Fraction of data to use for testing (e.g., 0.1 = 10%)\n",
    "- random_state – Seed value for reproducible splits\n",
    "\n",
    "We'll get back four return values:\n",
    "\n",
    "- X_train – Training set features (DataFrame)\n",
    "- X_test – Test set features (DataFrame)\n",
    "- y_train – Training set target values (Series)\n",
    "- y_test – Test set target values (Series)\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_X, df_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_X, df_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a9568",
   "metadata": {},
   "source": [
    "### 4.2 Train the model\n",
    "Create and fit a `LinearRegression` model.\n",
    "\n",
    "LinearRegression – A class from sklearn.linear_model that creates a linear regression model.\n",
    "\n",
    "model – An instance of the LinearRegression model. This object will store the learned coefficients and intercept after training.\n",
    "\n",
    "fit() – Trains the model by finding the best-fit line for the training data using the Ordinary Least Squares (OLS) method.\n",
    "\n",
    "X_train – The input features used to train the model.\n",
    "\n",
    "y_train – The target values used to train the model.\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676c419",
   "metadata": {},
   "source": [
    "Make predictions for the test set.\n",
    "\n",
    "The model.predict() method applies this equation to the X test data to compute predicted values.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred contains all the predicted values for all the rows in X_test based on the linear regression model.\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb721051",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168fff9",
   "metadata": {},
   "source": [
    "### 4.3 Report R^2, MAE, RMSE\n",
    "Evaluate the model using R^2, MAE, and RMSE.\n",
    "\n",
    "First:\n",
    "\n",
    "- Coefficient of Determination (R^2) - This tells you how well the model explains the variation in the target variable. A value close to 1 means the model fits the data well; a value close to 0 means the model doesn’t explain the variation well.\n",
    "\n",
    "\n",
    "Example code:\n",
    "  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R²: {r2:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import r2_score from sklearn.metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R² (Coefficient of Determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the R² value\n",
    "print(f'R²: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f529b",
   "metadata": {},
   "source": [
    "\n",
    "Second:\n",
    "\n",
    "- Mean Absolute Error (MAE) - This is the average of the absolute differences between the predicted values and the actual values. A smaller value means the model’s predictions are closer to the actual values.\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae:.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_absolute_error from sklearn.metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the MAE value\n",
    "print(f'MAE: {mae:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf1fd0",
   "metadata": {},
   "source": [
    "Third:\n",
    "\n",
    "- Root Mean Squared Error (RMSE) - This is the square root of the average of the squared differences between the predicted values and the actual values. It gives a sense of how far the predictions are from the actual values, with larger errors having more impact.\n",
    "\n",
    "Example code:\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error from sklearn.metrics to calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Print the RMSE value\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
